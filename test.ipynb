{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading movie-corpus to C:\\Users\\11632\\.convokit\\downloads\\movie-corpus\n",
      "Downloading movie-corpus from http://zissou.infosci.cornell.edu/convokit/datasets/movie-corpus/movie-corpus.zip (40.9MB)... Done\n"
     ]
    }
   ],
   "source": [
    "from convokit import Corpus, download\n",
    "corpus = Corpus(filename=download(\"movie-corpus\"))\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总话语数: 304713\n",
      "总对话数（会话数）: 83097\n",
      "对话ID: L1044\n",
      "u0: They do not!\n",
      "u2: They do to!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"总话语数:\", len(corpus.utterances))\n",
    "print(\"总对话数（会话数）:\", len(corpus.conversations))\n",
    "\n",
    "\n",
    "for conversation_id in corpus.conversations:\n",
    "    conversation = corpus.get_conversation(conversation_id)\n",
    "    print(f\"对话ID: {conversation_id}\")\n",
    "    for utterance in conversation.iter_utterances():\n",
    "        print(f\"{utterance.speaker.id}: {utterance.text}\")\n",
    "    break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations_texts = []\n",
    "\n",
    "# \n",
    "for i, conversation_id in enumerate(corpus.conversations):\n",
    "    if i >= 10000:  \n",
    "        break\n",
    "    conversation = corpus.get_conversation(conversation_id)\n",
    "   \n",
    "    conversation_text = ' '.join([utterance.text for utterance in conversation.iter_utterances()])\n",
    "    conversations_texts.append(conversation_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "# create a tokenizer\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502498\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = encoding.encode(\"\".join(conversations_texts))\n",
    "\n",
    "print(len(tokenized_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([502498])\n",
      "100252\n"
     ]
    }
   ],
   "source": [
    "#convert to tensor\n",
    "tokenized_text = torch.tensor(tokenized_text)\n",
    "print(tokenized_text.shape)\n",
    "max_token_value = tokenized_text.max().item()\n",
    "print(max_token_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and validation sets\n",
    "train_idex = int(len(tokenized_text) * 0.9)\n",
    "train_data = tokenized_text[:train_idex]\n",
    "valid_data = tokenized_text[train_idex:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "context_size = 64\n",
    "d_model = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly extract a batch of data from train data\n",
    "data = train_data\n",
    "idxs = torch.randint(0 , len(data) - context_size, size = (batch_size,))\n",
    "x_batch = torch.stack([data[idx:idx + context_size] for idx in idxs])\n",
    "y_batch = torch.stack([data[idx + 1 :idx + context_size + 1] for idx in idxs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1472</td>\n",
       "      <td>7095</td>\n",
       "      <td>420</td>\n",
       "      <td>17781</td>\n",
       "      <td>276</td>\n",
       "      <td>7564</td>\n",
       "      <td>30</td>\n",
       "      <td>15546</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>46552</td>\n",
       "      <td>13</td>\n",
       "      <td>2435</td>\n",
       "      <td>1541</td>\n",
       "      <td>956</td>\n",
       "      <td>3504</td>\n",
       "      <td>46552</td>\n",
       "      <td>13</td>\n",
       "      <td>8155</td>\n",
       "      <td>1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6010</td>\n",
       "      <td>279</td>\n",
       "      <td>3215</td>\n",
       "      <td>11</td>\n",
       "      <td>6958</td>\n",
       "      <td>279</td>\n",
       "      <td>8957</td>\n",
       "      <td>11</td>\n",
       "      <td>704</td>\n",
       "      <td>4131</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>2209</td>\n",
       "      <td>433</td>\n",
       "      <td>922</td>\n",
       "      <td>856</td>\n",
       "      <td>18311</td>\n",
       "      <td>30</td>\n",
       "      <td>3234</td>\n",
       "      <td>499</td>\n",
       "      <td>4059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>584</td>\n",
       "      <td>1288</td>\n",
       "      <td>387</td>\n",
       "      <td>3339</td>\n",
       "      <td>21300</td>\n",
       "      <td>430</td>\n",
       "      <td>8530</td>\n",
       "      <td>649</td>\n",
       "      <td>956</td>\n",
       "      <td>387</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7566</td>\n",
       "      <td>11</td>\n",
       "      <td>568</td>\n",
       "      <td>596</td>\n",
       "      <td>1633</td>\n",
       "      <td>10107</td>\n",
       "      <td>11</td>\n",
       "      <td>25237</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10177</td>\n",
       "      <td>13</td>\n",
       "      <td>4946</td>\n",
       "      <td>499</td>\n",
       "      <td>1935</td>\n",
       "      <td>1521</td>\n",
       "      <td>9477</td>\n",
       "      <td>311</td>\n",
       "      <td>3441</td>\n",
       "      <td>291</td>\n",
       "      <td>...</td>\n",
       "      <td>279</td>\n",
       "      <td>7858</td>\n",
       "      <td>13</td>\n",
       "      <td>578</td>\n",
       "      <td>15653</td>\n",
       "      <td>1051</td>\n",
       "      <td>12886</td>\n",
       "      <td>311</td>\n",
       "      <td>2564</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27074</td>\n",
       "      <td>1102</td>\n",
       "      <td>596</td>\n",
       "      <td>499</td>\n",
       "      <td>11</td>\n",
       "      <td>6941</td>\n",
       "      <td>1196</td>\n",
       "      <td>484</td>\n",
       "      <td>499</td>\n",
       "      <td>387</td>\n",
       "      <td>...</td>\n",
       "      <td>4671</td>\n",
       "      <td>754</td>\n",
       "      <td>3156</td>\n",
       "      <td>279</td>\n",
       "      <td>7205</td>\n",
       "      <td>77799</td>\n",
       "      <td>596</td>\n",
       "      <td>41100</td>\n",
       "      <td>374</td>\n",
       "      <td>30831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>311</td>\n",
       "      <td>387</td>\n",
       "      <td>11594</td>\n",
       "      <td>13</td>\n",
       "      <td>1472</td>\n",
       "      <td>4934</td>\n",
       "      <td>757</td>\n",
       "      <td>311</td>\n",
       "      <td>6604</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>8595</td>\n",
       "      <td>3287</td>\n",
       "      <td>956</td>\n",
       "      <td>499</td>\n",
       "      <td>3371</td>\n",
       "      <td>757</td>\n",
       "      <td>499</td>\n",
       "      <td>1436</td>\n",
       "      <td>1373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>449</td>\n",
       "      <td>433</td>\n",
       "      <td>13</td>\n",
       "      <td>358</td>\n",
       "      <td>3077</td>\n",
       "      <td>1027</td>\n",
       "      <td>1405</td>\n",
       "      <td>499</td>\n",
       "      <td>3077</td>\n",
       "      <td>1027</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>3053</td>\n",
       "      <td>358</td>\n",
       "      <td>2586</td>\n",
       "      <td>304</td>\n",
       "      <td>30</td>\n",
       "      <td>8840</td>\n",
       "      <td>11</td>\n",
       "      <td>358</td>\n",
       "      <td>3463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>1314</td>\n",
       "      <td>30</td>\n",
       "      <td>220</td>\n",
       "      <td>358</td>\n",
       "      <td>2019</td>\n",
       "      <td>358</td>\n",
       "      <td>2751</td>\n",
       "      <td>279</td>\n",
       "      <td>83590</td>\n",
       "      <td>...</td>\n",
       "      <td>220</td>\n",
       "      <td>3011</td>\n",
       "      <td>596</td>\n",
       "      <td>1148</td>\n",
       "      <td>814</td>\n",
       "      <td>2019</td>\n",
       "      <td>13</td>\n",
       "      <td>220</td>\n",
       "      <td>358</td>\n",
       "      <td>2751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1      2      3      4     5     6      7     8      9   ...  \\\n",
       "0   1472  7095    420  17781    276  7564    30  15546    64     11  ...   \n",
       "1   6010   279   3215     11   6958   279  8957     11   704   4131  ...   \n",
       "2    584  1288    387   3339  21300   430  8530    649   956    387  ...   \n",
       "3  10177    13   4946    499   1935  1521  9477    311  3441    291  ...   \n",
       "4  27074  1102    596    499     11  6941  1196    484   499    387  ...   \n",
       "5    311   387  11594     13   1472  4934   757    311  6604     11  ...   \n",
       "6    449   433     13    358   3077  1027  1405    499  3077   1027  ...   \n",
       "7     11  1314     30    220    358  2019   358   2751   279  83590  ...   \n",
       "\n",
       "      54    55    56    57     58     59     60     61     62     63  \n",
       "0  46552    13  2435  1541    956   3504  46552     13   8155   1060  \n",
       "1     13  2209   433   922    856  18311     30   3234    499   4059  \n",
       "2      0  7566    11   568    596   1633  10107     11  25237     13  \n",
       "3    279  7858    13   578  15653   1051  12886    311   2564    459  \n",
       "4   4671   754  3156   279   7205  77799    596  41100    374  30831  \n",
       "5     30  8595  3287   956    499   3371    757    499   1436   1373  \n",
       "6     13  3053   358  2586    304     30   8840     11    358   3463  \n",
       "7    220  3011   596  1148    814   2019     13    220    358   2751  \n",
       "\n",
       "[8 rows x 64 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(x_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Press the button, pull the chain, out comes a chocolate choo-choo train.' I'll tell you all in due time, after we make love. But first, tell me another poem. Damn. What exactly do you do at Virtucon? Yes. Is it about my teeth? Do you mind\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.decode(x_batch[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-4.8394e-01, -7.6046e-01, -1.9887e+00,  ..., -9.9964e-01,\n",
      "          1.0187e+00, -1.3358e+00],\n",
      "        [ 8.7920e-01, -6.9954e-02,  1.2484e+00,  ...,  1.3967e+00,\n",
      "          1.2531e+00,  1.0986e+00],\n",
      "        [ 1.2006e+00,  2.8766e-01, -8.3681e-03,  ...,  9.2995e-02,\n",
      "          6.2513e-01, -1.9700e+00],\n",
      "        ...,\n",
      "        [ 7.0170e-01,  8.1568e-01, -1.3715e+00,  ..., -2.5522e-01,\n",
      "         -7.8283e-01,  2.0525e-01],\n",
      "        [ 6.9547e-01, -2.8896e-02, -5.7622e-01,  ...,  6.8268e-04,\n",
      "          1.0790e-01,  1.1045e+00],\n",
      "        [ 1.2116e+00, -9.4703e-02,  9.7930e-01,  ...,  1.4197e+00,\n",
      "          4.0194e-01,  1.5323e+00]], requires_grad=True)\n",
      "torch.Size([8, 64, 64])\n",
      "torch.Size([8, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "#embedding 层\n",
    "''' \n",
    "embedding层的作用是将单词嵌入为语义向量，它的输入是模型的输入X。输出单词的语义信息。\n",
    "\n",
    "在gpt使用的Transformer中，语义分为两种，一是单词本身语义，二是单词所处位置的语义。\n",
    "\n",
    "换句话说，上次的预测结果提供两种信息\n",
    "\n",
    "1.词语是什么？\n",
    "2.词语的位置是什么？\n",
    "\n",
    "'''\n",
    "\n",
    "token_embedding_table = torch.nn.Embedding(max_token_value + 1, d_model)\n",
    "#打印embedding层的权重\n",
    "print(token_embedding_table.weight)\n",
    "x_batch_embedding = token_embedding_table(x_batch)\n",
    "y_batch_embedding = token_embedding_table(y_batch)\n",
    "print(x_batch_embedding.shape)\n",
    "print(y_batch_embedding.shape)\n",
    "\n",
    "#形状： X,T,C\n",
    "#X: batch_size 批次大小\n",
    "#T: context_size 上下文大小，序列长度，时间步\n",
    "#C: d_model 词向量维度\n",
    "\n",
    "\n",
    "#获取位置编码\n",
    "position_encoding = torch.nn.Embedding(context_size, d_model)\n",
    "print(position_encoding.weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CUDA",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
