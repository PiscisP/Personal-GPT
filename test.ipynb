{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading movie-corpus to C:\\Users\\11632\\.convokit\\downloads\\movie-corpus\n",
      "Downloading movie-corpus from http://zissou.infosci.cornell.edu/convokit/datasets/movie-corpus/movie-corpus.zip (40.9MB)... Done\n"
     ]
    }
   ],
   "source": [
    "from convokit import Corpus, download\n",
    "corpus = Corpus(filename=download(\"movie-corpus\"))\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总话语数: 304713\n",
      "总对话数（会话数）: 83097\n",
      "对话ID: L1044\n",
      "u0: They do not!\n",
      "u2: They do to!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"总话语数:\", len(corpus.utterances))\n",
    "print(\"总对话数（会话数）:\", len(corpus.conversations))\n",
    "\n",
    "\n",
    "for conversation_id in corpus.conversations:\n",
    "    conversation = corpus.get_conversation(conversation_id)\n",
    "    print(f\"对话ID: {conversation_id}\")\n",
    "    for utterance in conversation.iter_utterances():\n",
    "        print(f\"{utterance.speaker.id}: {utterance.text}\")\n",
    "    break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations_texts = []\n",
    "\n",
    "# \n",
    "for i, conversation_id in enumerate(corpus.conversations):\n",
    "    if i >= 10000:  \n",
    "        break\n",
    "    conversation = corpus.get_conversation(conversation_id)\n",
    "   \n",
    "    conversation_text = ' '.join([utterance.text for utterance in conversation.iter_utterances()])\n",
    "    conversations_texts.append(conversation_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "# create a tokenizer\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502498\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = encoding.encode(\"\".join(conversations_texts))\n",
    "\n",
    "print(len(tokenized_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([502498])\n",
      "100252\n"
     ]
    }
   ],
   "source": [
    "#convert to tensor\n",
    "tokenized_text = torch.tensor(tokenized_text)\n",
    "print(tokenized_text.shape)\n",
    "max_token_value = tokenized_text.max().item()\n",
    "print(max_token_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and validation sets\n",
    "train_idex = int(len(tokenized_text) * 0.9)\n",
    "train_data = tokenized_text[:train_idex]\n",
    "valid_data = tokenized_text[train_idex:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "context_size = 64\n",
    "d_model = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly extract a batch of data from train data\n",
    "data = train_data\n",
    "idxs = torch.randint(0 , len(data) - context_size, size = (batch_size,))\n",
    "x_batch = torch.stack([data[idx:idx + context_size] for idx in idxs])\n",
    "y_batch = torch.stack([data[idx + 1 :idx + context_size + 1] for idx in idxs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>433</td>\n",
       "      <td>13912</td>\n",
       "      <td>757</td>\n",
       "      <td>505</td>\n",
       "      <td>3515</td>\n",
       "      <td>311</td>\n",
       "      <td>2274</td>\n",
       "      <td>459</td>\n",
       "      <td>5150</td>\n",
       "      <td>17743</td>\n",
       "      <td>...</td>\n",
       "      <td>358</td>\n",
       "      <td>2846</td>\n",
       "      <td>2771</td>\n",
       "      <td>499</td>\n",
       "      <td>1053</td>\n",
       "      <td>13</td>\n",
       "      <td>35272</td>\n",
       "      <td>596</td>\n",
       "      <td>2751</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>596</td>\n",
       "      <td>4648</td>\n",
       "      <td>21908</td>\n",
       "      <td>3639</td>\n",
       "      <td>30</td>\n",
       "      <td>25797</td>\n",
       "      <td>893</td>\n",
       "      <td>11</td>\n",
       "      <td>374</td>\n",
       "      <td>568</td>\n",
       "      <td>...</td>\n",
       "      <td>311</td>\n",
       "      <td>757</td>\n",
       "      <td>11</td>\n",
       "      <td>1314</td>\n",
       "      <td>994</td>\n",
       "      <td>682</td>\n",
       "      <td>279</td>\n",
       "      <td>17619</td>\n",
       "      <td>574</td>\n",
       "      <td>5108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5519</td>\n",
       "      <td>499</td>\n",
       "      <td>1440</td>\n",
       "      <td>1405</td>\n",
       "      <td>430</td>\n",
       "      <td>4751</td>\n",
       "      <td>4131</td>\n",
       "      <td>505</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>499</td>\n",
       "      <td>649</td>\n",
       "      <td>439</td>\n",
       "      <td>433</td>\n",
       "      <td>5900</td>\n",
       "      <td>555</td>\n",
       "      <td>323</td>\n",
       "      <td>279</td>\n",
       "      <td>6037</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>311</td>\n",
       "      <td>6068</td>\n",
       "      <td>279</td>\n",
       "      <td>4359</td>\n",
       "      <td>15770</td>\n",
       "      <td>6166</td>\n",
       "      <td>13</td>\n",
       "      <td>54652</td>\n",
       "      <td>1514</td>\n",
       "      <td>258</td>\n",
       "      <td>...</td>\n",
       "      <td>1603</td>\n",
       "      <td>499</td>\n",
       "      <td>1027</td>\n",
       "      <td>264</td>\n",
       "      <td>1520</td>\n",
       "      <td>311</td>\n",
       "      <td>757</td>\n",
       "      <td>13</td>\n",
       "      <td>4718</td>\n",
       "      <td>11091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>264</td>\n",
       "      <td>9396</td>\n",
       "      <td>912</td>\n",
       "      <td>22622</td>\n",
       "      <td>1109</td>\n",
       "      <td>872</td>\n",
       "      <td>25015</td>\n",
       "      <td>13</td>\n",
       "      <td>22335</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>555</td>\n",
       "      <td>3026</td>\n",
       "      <td>1006</td>\n",
       "      <td>12337</td>\n",
       "      <td>11</td>\n",
       "      <td>36823</td>\n",
       "      <td>42407</td>\n",
       "      <td>13</td>\n",
       "      <td>2435</td>\n",
       "      <td>1051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>477</td>\n",
       "      <td>499</td>\n",
       "      <td>1253</td>\n",
       "      <td>5387</td>\n",
       "      <td>369</td>\n",
       "      <td>81801</td>\n",
       "      <td>16986</td>\n",
       "      <td>11</td>\n",
       "      <td>389</td>\n",
       "      <td>832</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>13440</td>\n",
       "      <td>477</td>\n",
       "      <td>539</td>\n",
       "      <td>499</td>\n",
       "      <td>12265</td>\n",
       "      <td>374</td>\n",
       "      <td>11</td>\n",
       "      <td>315</td>\n",
       "      <td>3388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5270</td>\n",
       "      <td>13</td>\n",
       "      <td>8595</td>\n",
       "      <td>30</td>\n",
       "      <td>3639</td>\n",
       "      <td>596</td>\n",
       "      <td>304</td>\n",
       "      <td>81801</td>\n",
       "      <td>30</td>\n",
       "      <td>578</td>\n",
       "      <td>...</td>\n",
       "      <td>389</td>\n",
       "      <td>279</td>\n",
       "      <td>42632</td>\n",
       "      <td>11</td>\n",
       "      <td>36346</td>\n",
       "      <td>30</td>\n",
       "      <td>4438</td>\n",
       "      <td>95950</td>\n",
       "      <td>499</td>\n",
       "      <td>527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11471</td>\n",
       "      <td>13</td>\n",
       "      <td>2435</td>\n",
       "      <td>2351</td>\n",
       "      <td>5710</td>\n",
       "      <td>13</td>\n",
       "      <td>2435</td>\n",
       "      <td>4265</td>\n",
       "      <td>387</td>\n",
       "      <td>1618</td>\n",
       "      <td>...</td>\n",
       "      <td>956</td>\n",
       "      <td>1390</td>\n",
       "      <td>499</td>\n",
       "      <td>369</td>\n",
       "      <td>264</td>\n",
       "      <td>4333</td>\n",
       "      <td>76241</td>\n",
       "      <td>922</td>\n",
       "      <td>757</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1      2      3      4      5      6      7      8      9   ...  \\\n",
       "0    433  13912    757    505   3515    311   2274    459   5150  17743  ...   \n",
       "1    596   4648  21908   3639     30  25797    893     11    374    568  ...   \n",
       "2      0   5519    499   1440   1405    430   4751   4131    505     30  ...   \n",
       "3    311   6068    279   4359  15770   6166     13  54652   1514    258  ...   \n",
       "4    264   9396    912  22622   1109    872  25015     13  22335     30  ...   \n",
       "5    477    499   1253   5387    369  81801  16986     11    389    832  ...   \n",
       "6   5270     13   8595     30   3639    596    304  81801     30    578  ...   \n",
       "7  11471     13   2435   2351   5710     13   2435   4265    387   1618  ...   \n",
       "\n",
       "     54     55     56     57     58     59     60     61    62     63  \n",
       "0   358   2846   2771    499   1053     13  35272    596  2751    430  \n",
       "1   311    757     11   1314    994    682    279  17619   574   5108  \n",
       "2   499    649    439    433   5900    555    323    279  6037    315  \n",
       "3  1603    499   1027    264   1520    311    757     13  4718  11091  \n",
       "4   555   3026   1006  12337     11  36823  42407     13  2435   1051  \n",
       "5    30  13440    477    539    499  12265    374     11   315   3388  \n",
       "6   389    279  42632     11  36346     30   4438  95950   499    527  \n",
       "7   956   1390    499    369    264   4333  76241    922   757     30  \n",
       "\n",
       "[8 rows x 64 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(x_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\'s death...\" What?Ah man, is he usin\\' that line now on you? What, you think he made that little gem up? Jesus Christ, I used to have to listen to my old man use that every morning. Y\\'know what Stephen said to me, right when all the shit was coming'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.decode(x_batch[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0175,  1.5166, -0.6578,  ...,  0.9956,  1.1948, -0.6840],\n",
      "        [-0.0458,  2.1350,  0.2176,  ...,  2.1543,  0.5076,  0.2751],\n",
      "        [ 0.2905, -0.5032, -0.3581,  ..., -1.0190,  0.2279, -0.7405],\n",
      "        ...,\n",
      "        [ 1.4330, -0.2527,  0.7946,  ..., -0.2061,  1.4529,  0.3016],\n",
      "        [ 0.8533, -0.1278, -2.3567,  ..., -0.6176, -1.3524, -0.0935],\n",
      "        [ 0.2570,  0.0777, -0.0776,  ..., -0.4184, -0.1594, -0.4233]],\n",
      "       requires_grad=True)\n",
      "torch.Size([8, 64, 64])\n",
      "torch.Size([8, 64, 64])\n",
      "Parameter containing:\n",
      "tensor([[ 0.3182, -1.6880, -1.3281,  ..., -0.3215,  0.2587, -0.1867],\n",
      "        [-0.0200,  1.6375, -0.5828,  ..., -0.5376,  1.1342,  0.6509],\n",
      "        [ 1.0112,  0.1976, -1.1066,  ..., -1.0429, -0.0309,  1.3762],\n",
      "        ...,\n",
      "        [-0.8707, -1.8437, -0.7408,  ...,  0.7956,  2.1323,  0.3430],\n",
      "        [ 0.3719,  1.7791, -0.6057,  ..., -0.2267, -1.6209, -0.7319],\n",
      "        [ 1.1740, -0.0482, -2.4479,  ..., -0.8374,  1.2912,  0.8960]],\n",
      "       requires_grad=True)\n",
      "torch.Size([64, 64])\n"
     ]
    }
   ],
   "source": [
    "#embedding 层\n",
    "''' \n",
    "embedding层的作用是将单词嵌入为语义向量，它的输入是模型的输入X。输出单词的语义信息。\n",
    "\n",
    "在gpt使用的Transformer中，语义分为两种，一是单词本身语义，二是单词所处位置的语义。\n",
    "\n",
    "换句话说，上次的预测结果提供两种信息\n",
    "\n",
    "1.词语是什么？\n",
    "2.词语的位置是什么？\n",
    "\n",
    "'''\n",
    "\n",
    "token_embedding_table = torch.nn.Embedding(max_token_value + 1, d_model)\n",
    "#打印embedding层的权重\n",
    "print(token_embedding_table.weight)\n",
    "x_batch_embedding = token_embedding_table(x_batch)\n",
    "y_batch_embedding = token_embedding_table(y_batch)\n",
    "print(x_batch_embedding.shape)\n",
    "print(y_batch_embedding.shape)\n",
    "\n",
    "#形状： X,T,C\n",
    "#X: batch_size 批次大小\n",
    "#T: context_size 上下文大小，序列长度，时间步\n",
    "#C: d_model 词向量维度\n",
    "\n",
    "'''\n",
    "position = torch.arange(0, context_size, dtype=torch.float).unsqueeze(1)\n",
    "div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "position_encoding = torch.zeros(context_size, d_model)\n",
    "position_encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "position_encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "position_encoding = position_encoding.unsqueeze(0).expand(batch_size, -1, -1)\n",
    "x = x_batch_embedding + position_encoding\n",
    "y = y_batch_embedding + position_encoding\n",
    "'''\n",
    "\n",
    "'''\n",
    "预先计算位置编码的值（而不是使用可训练的嵌入）的主要优点是我们的模型最终需要训练的参数更少。参数的减少可以提高训练性能\n",
    "'''\n",
    "#获取位置编码\n",
    "position_encoding = torch.nn.Embedding(context_size, d_model)\n",
    "print(position_encoding.weight)\n",
    "print(position_encoding.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multihead attention\n",
    "'''\n",
    "batch_size = 8\n",
    "context_size = 64\n",
    "d_model = 64\n",
    "'''\n",
    "num_heads = 4\n",
    "head_dim = d_model // num_heads  # 每个头的维度\n",
    "\n",
    "# 64 * 64\n",
    "Wq = torch.nn.Linear(d_model, d_model)\n",
    "Wk = torch.nn.Linear(d_model, d_model)\n",
    "Wv = torch.nn.Linear(d_model, d_model)\n",
    "\n",
    "Q = Wq(x_batch_embedding)\n",
    "K = Wk(x_batch_embedding)\n",
    "V = Wv(x_batch_embedding)\n",
    "\n",
    "# 将Q, K, V按照多头设置进行维度重排\n",
    "Q_multihead = Q.view(batch_size, context_size, num_heads, head_dim)\n",
    "Q_multihead = Q_multihead.transpose(1, 2)  # 将头的维度和上下文长度的维度交换\n",
    "\n",
    "K_multihead = K.view(batch_size, context_size, num_heads, head_dim)\n",
    "K_multihead = K_multihead.transpose(1, 2)\n",
    "\n",
    "V_multihead = V.view(batch_size, context_size, num_heads, head_dim)\n",
    "V_multihead = V_multihead.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64, 64])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = Q @ K.transpose(-2 , -1)\n",
    "wei.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CUDA",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
