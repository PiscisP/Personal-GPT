{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading movie-corpus to C:\\Users\\11632\\.convokit\\downloads\\movie-corpus\n",
      "Downloading movie-corpus from http://zissou.infosci.cornell.edu/convokit/datasets/movie-corpus/movie-corpus.zip (40.9MB)... Done\n"
     ]
    }
   ],
   "source": [
    "from convokit import Corpus, download\n",
    "corpus = Corpus(filename=download(\"movie-corpus\"))\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总话语数: 304713\n",
      "总对话数（会话数）: 83097\n",
      "对话ID: L1044\n",
      "u0: They do not!\n",
      "u2: They do to!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"总话语数:\", len(corpus.utterances))\n",
    "print(\"总对话数（会话数）:\", len(corpus.conversations))\n",
    "\n",
    "\n",
    "for conversation_id in corpus.conversations:\n",
    "    conversation = corpus.get_conversation(conversation_id)\n",
    "    print(f\"对话ID: {conversation_id}\")\n",
    "    for utterance in conversation.iter_utterances():\n",
    "        print(f\"{utterance.speaker.id}: {utterance.text}\")\n",
    "    break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations_texts = []\n",
    "\n",
    "# \n",
    "for i, conversation_id in enumerate(corpus.conversations):\n",
    "    if i >= 10000:  \n",
    "        break\n",
    "    conversation = corpus.get_conversation(conversation_id)\n",
    "   \n",
    "    conversation_text = ' '.join([utterance.text for utterance in conversation.iter_utterances()])\n",
    "    conversations_texts.append(conversation_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "# create a tokenizer\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502498\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = encoding.encode(\"\".join(conversations_texts))\n",
    "\n",
    "print(len(tokenized_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([502498])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11632\\AppData\\Local\\Temp\\ipykernel_28280\\1806850795.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tokenized_text = torch.tensor(tokenized_text)\n"
     ]
    }
   ],
   "source": [
    "#convert to tensor\n",
    "tokenized_text = torch.tensor(tokenized_text)\n",
    "print(tokenized_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and validation sets\n",
    "train_idex = int(len(tokenized_text) * 0.9)\n",
    "train_data = tokenized_text[:train_idex]\n",
    "valid_data = tokenized_text[train_idex:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "context_size = 64\n",
    "d_model = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly extract a batch of data from train data\n",
    "data = train_data\n",
    "idxs = torch.randint(0 , len(data) - context_size, size = (batch_size,))\n",
    "x_batch = torch.stack([data[idx:idx + context_size] for idx in idxs])\n",
    "y_batch = torch.stack([data[idx + 1 :idx + context_size + 1] for idx in idxs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45446</td>\n",
       "      <td>358</td>\n",
       "      <td>2733</td>\n",
       "      <td>5128</td>\n",
       "      <td>16917</td>\n",
       "      <td>922</td>\n",
       "      <td>420</td>\n",
       "      <td>13</td>\n",
       "      <td>3011</td>\n",
       "      <td>10578</td>\n",
       "      <td>...</td>\n",
       "      <td>2684</td>\n",
       "      <td>596</td>\n",
       "      <td>264</td>\n",
       "      <td>2763</td>\n",
       "      <td>315</td>\n",
       "      <td>15525</td>\n",
       "      <td>17619</td>\n",
       "      <td>304</td>\n",
       "      <td>1070</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1051</td>\n",
       "      <td>304</td>\n",
       "      <td>3021</td>\n",
       "      <td>13</td>\n",
       "      <td>220</td>\n",
       "      <td>1472</td>\n",
       "      <td>1440</td>\n",
       "      <td>1268</td>\n",
       "      <td>433</td>\n",
       "      <td>374</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>2876</td>\n",
       "      <td>422</td>\n",
       "      <td>279</td>\n",
       "      <td>1274</td>\n",
       "      <td>2349</td>\n",
       "      <td>3871</td>\n",
       "      <td>304</td>\n",
       "      <td>12976</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4423</td>\n",
       "      <td>369</td>\n",
       "      <td>264</td>\n",
       "      <td>2697</td>\n",
       "      <td>1418</td>\n",
       "      <td>13</td>\n",
       "      <td>358</td>\n",
       "      <td>3194</td>\n",
       "      <td>499</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>264</td>\n",
       "      <td>5128</td>\n",
       "      <td>40666</td>\n",
       "      <td>5743</td>\n",
       "      <td>315</td>\n",
       "      <td>1667</td>\n",
       "      <td>13</td>\n",
       "      <td>2100</td>\n",
       "      <td>1131</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9568</td>\n",
       "      <td>11</td>\n",
       "      <td>1095</td>\n",
       "      <td>757</td>\n",
       "      <td>1781</td>\n",
       "      <td>1131</td>\n",
       "      <td>3639</td>\n",
       "      <td>1051</td>\n",
       "      <td>499</td>\n",
       "      <td>5605</td>\n",
       "      <td>...</td>\n",
       "      <td>584</td>\n",
       "      <td>656</td>\n",
       "      <td>11</td>\n",
       "      <td>28146</td>\n",
       "      <td>30</td>\n",
       "      <td>578</td>\n",
       "      <td>892</td>\n",
       "      <td>374</td>\n",
       "      <td>4401</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4333</td>\n",
       "      <td>30</td>\n",
       "      <td>2100</td>\n",
       "      <td>11</td>\n",
       "      <td>358</td>\n",
       "      <td>2322</td>\n",
       "      <td>264</td>\n",
       "      <td>502</td>\n",
       "      <td>4333</td>\n",
       "      <td>17182</td>\n",
       "      <td>...</td>\n",
       "      <td>430</td>\n",
       "      <td>499</td>\n",
       "      <td>3077</td>\n",
       "      <td>1027</td>\n",
       "      <td>43759</td>\n",
       "      <td>25492</td>\n",
       "      <td>315</td>\n",
       "      <td>701</td>\n",
       "      <td>24099</td>\n",
       "      <td>5253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1093</td>\n",
       "      <td>430</td>\n",
       "      <td>30</td>\n",
       "      <td>1102</td>\n",
       "      <td>1253</td>\n",
       "      <td>617</td>\n",
       "      <td>7077</td>\n",
       "      <td>11</td>\n",
       "      <td>719</td>\n",
       "      <td>539</td>\n",
       "      <td>...</td>\n",
       "      <td>10466</td>\n",
       "      <td>323</td>\n",
       "      <td>97387</td>\n",
       "      <td>279</td>\n",
       "      <td>4027</td>\n",
       "      <td>6798</td>\n",
       "      <td>704</td>\n",
       "      <td>315</td>\n",
       "      <td>279</td>\n",
       "      <td>10054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4438</td>\n",
       "      <td>596</td>\n",
       "      <td>430</td>\n",
       "      <td>1131</td>\n",
       "      <td>19418</td>\n",
       "      <td>430</td>\n",
       "      <td>387</td>\n",
       "      <td>264</td>\n",
       "      <td>1695</td>\n",
       "      <td>3245</td>\n",
       "      <td>...</td>\n",
       "      <td>539</td>\n",
       "      <td>36380</td>\n",
       "      <td>4954</td>\n",
       "      <td>757</td>\n",
       "      <td>13</td>\n",
       "      <td>358</td>\n",
       "      <td>11471</td>\n",
       "      <td>13</td>\n",
       "      <td>220</td>\n",
       "      <td>1226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>220</td>\n",
       "      <td>16299</td>\n",
       "      <td>374</td>\n",
       "      <td>1633</td>\n",
       "      <td>6555</td>\n",
       "      <td>1606</td>\n",
       "      <td>433</td>\n",
       "      <td>706</td>\n",
       "      <td>279</td>\n",
       "      <td>2532</td>\n",
       "      <td>...</td>\n",
       "      <td>1131</td>\n",
       "      <td>9514</td>\n",
       "      <td>1440</td>\n",
       "      <td>1131</td>\n",
       "      <td>7566</td>\n",
       "      <td>0</td>\n",
       "      <td>1628</td>\n",
       "      <td>358</td>\n",
       "      <td>574</td>\n",
       "      <td>20910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1     2     3      4     5     6     7     8      9   ...     54  \\\n",
       "0  45446    358  2733  5128  16917   922   420    13  3011  10578  ...   2684   \n",
       "1   1051    304  3021    13    220  1472  1440  1268   433    374  ...     13   \n",
       "2   4423    369   264  2697   1418    13   358  3194   499     13  ...    264   \n",
       "3   9568     11  1095   757   1781  1131  3639  1051   499   5605  ...    584   \n",
       "4   4333     30  2100    11    358  2322   264   502  4333  17182  ...    430   \n",
       "5   1093    430    30  1102   1253   617  7077    11   719    539  ...  10466   \n",
       "6   4438    596   430  1131  19418   430   387   264  1695   3245  ...    539   \n",
       "7    220  16299   374  1633   6555  1606   433   706   279   2532  ...   1131   \n",
       "\n",
       "      55     56     57     58     59     60    61     62     63  \n",
       "0    596    264   2763    315  15525  17619   304   1070     11  \n",
       "1   2876    422    279   1274   2349   3871   304  12976    311  \n",
       "2   5128  40666   5743    315   1667     13  2100   1131    499  \n",
       "3    656     11  28146     30    578    892   374   4401    704  \n",
       "4    499   3077   1027  43759  25492    315   701  24099   5253  \n",
       "5    323  97387    279   4027   6798    704   315    279  10054  \n",
       "6  36380   4954    757     13    358  11471    13    220   1226  \n",
       "7   9514   1440   1131   7566      0   1628   358    574  20910  \n",
       "\n",
       "[8 rows x 64 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(x_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" were in love.  You know how it is when you laugh all the time. Then the relationship remains the same and the love changes only when there's change in the two people who share that love. Sure.  But that's only when the love itself goes unchanged. Not if the people change together in relation to\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.decode(x_batch[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CUDA",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
